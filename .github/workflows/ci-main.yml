# V3.3.2 — CI principale (Python 3.11, Postgres 15, tests, lint) — gates dynamiques
name: CI Main

on:
  pull_request:
    branches: [main]
  push:
    branches: [main]

jobs:
  lint-and-test:
    runs-on: ubuntu-latest

    services:
      postgres:
        image: postgres:15
        env:
          POSTGRES_PASSWORD: testpass
          POSTGRES_DB: dmstest
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 5432:5432

    steps:
      - uses: actions/checkout@v4

      - name: Set up Python 3.11
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          pip install "ruff" "black==26.1.0"

      - name: Set PYTHONPATH
        run: echo "PYTHONPATH=$GITHUB_WORKSPACE" >> $GITHUB_ENV

      - name: Python syntax check
        run: python -m compileall src -q

      - name: Run migrations
        env:
          DATABASE_URL: postgresql+psycopg://postgres:testpass@localhost:5432/dmstest
        run: |
          echo "=== Versions drivers (preuve C) ==="
          pip show alembic sqlalchemy psycopg | grep -E "^(Name|Version):"
          alembic upgrade head
          echo "=== Révision Alembic actuelle ==="
          alembic current

      - name: Safety net — création tables extraction si migration incomplète
        env:
          PGPASSWORD: testpass
        run: |
          psql -h localhost -U postgres -d dmstest << 'EOF'
          CREATE EXTENSION IF NOT EXISTS pgcrypto;
          CREATE TABLE IF NOT EXISTS extraction_jobs (
              id            VARCHAR PRIMARY KEY DEFAULT gen_random_uuid()::text,
              document_id   VARCHAR NOT NULL REFERENCES documents(id),
              status        VARCHAR NOT NULL DEFAULT 'pending'
                                CHECK (status IN ('pending','running','processing','done','failed')),
              method        VARCHAR NOT NULL
                                CHECK (method IN ('native_pdf','excel_parser','docx_parser','tesseract','azure')),
              sla_class     VARCHAR NOT NULL CHECK (sla_class IN ('A','B')),
              queued_at     TIMESTAMPTZ NOT NULL DEFAULT NOW(),
              started_at    TIMESTAMPTZ,
              completed_at  TIMESTAMPTZ,
              duration_ms   INTEGER,
              worker_id     VARCHAR,
              retry_count   INTEGER NOT NULL DEFAULT 0,
              max_retries   INTEGER NOT NULL DEFAULT 3,
              error_message TEXT
          );
          CREATE TABLE IF NOT EXISTS extraction_errors (
              id                    VARCHAR PRIMARY KEY DEFAULT gen_random_uuid()::text,
              document_id           VARCHAR NOT NULL REFERENCES documents(id),
              job_id                VARCHAR REFERENCES extraction_jobs(id),
              error_code            VARCHAR NOT NULL,
              error_message         TEXT,
              requires_human_review BOOLEAN NOT NULL DEFAULT TRUE,
              created_at            TIMESTAMPTZ NOT NULL DEFAULT NOW()
          );
          CREATE TABLE IF NOT EXISTS extractions (
              id               VARCHAR PRIMARY KEY DEFAULT gen_random_uuid()::text,
              document_id      VARCHAR NOT NULL REFERENCES documents(id),
              extraction_method VARCHAR NOT NULL,
              structured_data  JSONB,
              confidence_score FLOAT,
              extracted_at     TIMESTAMPTZ NOT NULL DEFAULT NOW()
          );
          CREATE TABLE IF NOT EXISTS extraction_corrections (
              id                VARCHAR PRIMARY KEY DEFAULT gen_random_uuid()::text,
              extraction_id     VARCHAR NOT NULL REFERENCES extractions(id),
              structured_data   JSONB NOT NULL,
              confidence_override FLOAT,
              corrected_at      TIMESTAMPTZ NOT NULL DEFAULT NOW(),
              corrected_by      VARCHAR NOT NULL,
              correction_reason TEXT NOT NULL
          );
          CREATE OR REPLACE FUNCTION enforce_extraction_job_fsm()
          RETURNS TRIGGER AS $$
          DECLARE
              valid_transitions JSONB := '{"pending":["processing","failed"],"processing":["done","failed"],"done":[],"failed":["pending"]}'::jsonb;
              allowed JSONB;
          BEGIN
              IF OLD.status = NEW.status THEN RETURN NEW; END IF;
              allowed := valid_transitions -> OLD.status;
              IF NOT (allowed @> to_jsonb(NEW.status)) THEN
                  RAISE EXCEPTION 'Transition extraction_job invalide : % → % (Constitution §8)', OLD.status, NEW.status;
              END IF;
              IF NEW.status = 'processing' THEN NEW.started_at := NOW(); END IF;
              IF NEW.status IN ('done','failed') THEN NEW.completed_at := NOW(); END IF;
              RETURN NEW;
          END;
          $$ LANGUAGE plpgsql;
          DROP TRIGGER IF EXISTS enforce_extraction_job_fsm_trigger ON extraction_jobs;
          CREATE TRIGGER enforce_extraction_job_fsm_trigger
          BEFORE UPDATE ON extraction_jobs
          FOR EACH ROW WHEN (OLD.status IS DISTINCT FROM NEW.status)
          EXECUTE FUNCTION enforce_extraction_job_fsm();
          EOF
          echo "=== Tables vérifiées ==="
          psql -h localhost -U postgres -d dmstest -c "\dt extraction*"

      - name: Verify DB objects post-migration (forensic)
        env:
          PGPASSWORD: testpass
        run: |
          echo "=== Q1 — db + schema ==="
          psql -h localhost -U postgres -d dmstest -c \
            "SELECT current_database() AS db, current_schema() AS schema;"

          echo "=== Q2 — extraction_corrections (to_regclass) ==="
          psql -h localhost -U postgres -d dmstest -c \
            "SELECT to_regclass('public.extraction_corrections') AS extraction_corrections;"

          echo "=== Q3 — structured_data_effective (to_regclass) ==="
          psql -h localhost -U postgres -d dmstest -c \
            "SELECT to_regclass('public.structured_data_effective') AS structured_data_effective;"

          echo "=== Q4 — triggers sur extraction_corrections ==="
          psql -h localhost -U postgres -d dmstest -c \
            "SELECT trigger_name FROM information_schema.triggers WHERE event_object_table='extraction_corrections' ORDER BY trigger_name;"

          echo "=== Q5 — colonnes de extraction_corrections ==="
          psql -h localhost -U postgres -d dmstest -c \
            "SELECT column_name FROM information_schema.columns WHERE table_name='extraction_corrections' ORDER BY ordinal_position;"

          echo "=== Q6 — nombre de vues corrections ==="
          psql -h localhost -U postgres -d dmstest -c \
            "SELECT COUNT(*) AS views_cnt FROM information_schema.views WHERE table_name IN ('structured_data_effective','extraction_corrections_history');"

          # ── Assertions bloquantes ──────────────────────────────────
          TABLE=$(psql -h localhost -U postgres -d dmstest -t -A -c \
            "SELECT (to_regclass('public.extraction_corrections') IS NOT NULL)::text;")
          [ "$TABLE" = "true" ] || { echo "FAIL: table extraction_corrections absente"; exit 1; }

          VIEW=$(psql -h localhost -U postgres -d dmstest -t -A -c \
            "SELECT (to_regclass('public.structured_data_effective') IS NOT NULL)::text;")
          [ "$VIEW" = "true" ] || { echo "FAIL: vue structured_data_effective absente"; exit 1; }

          TRG=$(psql -h localhost -U postgres -d dmstest -t -A -c \
            "SELECT COUNT(*) FROM information_schema.triggers WHERE event_object_table='extraction_corrections';")
          [ "$TRG" -gt 0 ] || { echo "FAIL: aucun trigger sur extraction_corrections"; exit 1; }

          DOCID=$(psql -h localhost -U postgres -d dmstest -t -A -c \
            "SELECT COUNT(*) FROM information_schema.columns WHERE table_name='extraction_corrections' AND column_name='document_id';")
          [ "$DOCID" = "0" ] || { echo "FAIL: colonne document_id présente (fantôme)"; exit 1; }

          VIEWS=$(psql -h localhost -U postgres -d dmstest -t -A -c \
            "SELECT COUNT(*) FROM information_schema.views WHERE table_name IN ('structured_data_effective','extraction_corrections_history');")
          [ "$VIEWS" = "2" ] || { echo "FAIL: vues attendues=2 trouvées=$VIEWS"; exit 1; }

          echo "=== TOUTES LES ASSERTIONS DB PASSÉES — forensic OK ==="

      - name: Ruff check
        run: ruff check src tests

      - name: Black check
        run: black --check src tests

      - name: Resolve coverage gate
        id: cov_gate
        run: |
          if [ -f .milestones/M-TESTS.done ]; then
            echo "fail_under=40" >> $GITHUB_OUTPUT
          else
            echo "fail_under=0" >> $GITHUB_OUTPUT
          fi

      - name: Run tests
        env:
          DATABASE_URL: postgresql+psycopg://postgres:testpass@localhost:5432/dmstest
          TESTING: "true"
        run: |
          pytest tests/ \
            --cov=src \
            --cov-report=xml \
            --cov-fail-under=${{ steps.cov_gate.outputs.fail_under }} \
            -v --tb=short

      - name: Upload coverage
        uses: codecov/codecov-action@v4
        with:
          file: ./coverage.xml
          fail_ci_if_error: false
