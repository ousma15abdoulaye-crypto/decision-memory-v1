ADR-0005 â€” FINAL FREEZE OFFICIEL
Decision Memory System V3.3.2 â€” BÃ©tonisation ComplÃ¨te

Identifiant    : ADR-0005
Statut         : FROZEN âœ…
Date freeze    : 2026-02-20
Auteur         : Abdoulaye Ousmane (Founder & CTO)
Constitution   : V3.3.2 (canonique, frozen)
PrÃ©cÃ©dents     : ADR-0001 Â· ADR-0002 Â· ADR-0003 Â· ADR-0004
Objet          : BÃ©tonisation sÃ©curitÃ© + append-only cohÃ©rent +
                 extraction typÃ©e + dictionnaire Sahel vÃ©rifiÃ© +
                 dÃ©blocage PR #85
Sources audit  : Audit Senior 2026-02-19 + Review ChatGPT + Errata CTO
Fichier        : docs/adrs/ADR-0005.md
Freeze tag     : v3.3.2-adr0005-frozen
0. Pourquoi ce document
L'audit senior du 2026-02-19 + la review externe ont identifiÃ© :

7 failles systÃ©miques (FS-01 Ã  FS-07)
10 failles techniques (FT-01 Ã  FT-10)
4 contradictions critiques (C1 Ã  C4) dans la premiÃ¨re version de l'ADR
Sans ce document gelÃ©, les risques immÃ©diats sont :

Risque	Impact
JWT secret public en prod	Auth contournable
UPSERT sur table append-only	Crash scoring dÃ¨s 2e exÃ©cution
return [] ambigu extraction	Faux vide indÃ©tectable
Tables extraction_jobs/documents manquantes	PR #85 bloquÃ©e depuis 9h
create_user crash RETURNING	Inscription impossible
Seeds mercuriale incorrects	Couche B ancrÃ©e sur du faux
1. DÃ©cisions gelÃ©es
ID	DÃ©cision	Opposable
D1	Toute table immuable : trigger BEFORE UPDATE/DELETE	Oui
D2	Scoring : score_runs (Ã©vÃ©nements) + vue current_supplier_scores	Oui
D3	extract_dao_criteria_structured() retourne ExtractionResult â€” jamais []	Oui
D4	Seeds mercuriale : code exact + prix vÃ©rifiÃ© PDF + source_page obligatoire	Oui
D5	Migrations Alembic exÃ©cutÃ©es AVANT pytest en CI	Oui
D6	create_user utilise RETURNING id â€” jamais result.fetchone() sur None	Oui
RÃˆGLE-001	ZÃ©ro valeur mercuriale insÃ©rÃ©e de mÃ©moire sans vÃ©rification PDF	Oui
2. DÃ‰BLOCAGE PR #85 â€” Fixes immÃ©diats (aujourd'hui)
2.1 â€” Tables manquantes : migrations avant tests
Erreur :


psycopg.errors.UndefinedTable: relation "extraction_jobs" does not exist
psycopg.errors.UndefinedTable: relation "extraction_errors" does not exist
psycopg.errors.UndefinedTable: relation "documents" does not exist
Cause : Alembic non exÃ©cutÃ© avant pytest en CI.

Fix CI â€” .github/workflows/ci_main.yml :


jobs:
  lint-and-test:
    steps:
      # ... (checkout, setup python, install deps) ...

      - name: Run Alembic migrations
        run: alembic upgrade head
        env:
          DATABASE_URL: ${{ secrets.DATABASE_URL }}

      # APRÃˆS les migrations â€” jamais avant
      - name: Run tests
        run: |
          pytest tests/ -x -q \
            --cov=src \
            --cov-report=xml \
            --cov-fail-under=5
        env:
          DATABASE_URL: ${{ secrets.DATABASE_URL }}
Fix conftest intÃ©gration â€” tests/integration/conftest.py :


import subprocess
import pytest


@pytest.fixture(scope="session", autouse=True)
def run_migrations_before_integration_tests():
    """
    Garantit que toutes les migrations sont appliquÃ©es
    avant les tests d'intÃ©gration.
    Constitution Â§9 : Ã©chec explicite si migrations Ã©chouent.
    """
    result = subprocess.run(
        ["alembic", "upgrade", "head"],
        capture_output=True,
        text=True,
    )
    if result.returncode != 0:
        pytest.fail(
            f"Migrations Alembic Ã©chouÃ©es â€” tests d'intÃ©gration impossibles.\n"
            f"stdout : {result.stdout}\n"
            f"stderr : {result.stderr}"
        )
    yield
    # Pas de rollback â€” DB de test rÃ©initialisÃ©e par le workflow CI
2.2 â€” create_user : crash NoneType.fetchone()
Erreur :


src/auth.py:234: in create_user
    user_id = result.fetchone()[0]
E   AttributeError: 'NoneType' object has no attribute 'fetchone'
Cause : psycopg3 retourne None depuis cur.execute(). Il faut utiliser cur.fetchone() aprÃ¨s.

Fix src/auth.py :


from src.db.core import get_db_cursor


def create_user(
    username: str,
    email: str,
    password: str,
    role: str = "procurement_officer",
) -> dict:
    """
    CrÃ©e un utilisateur. Retourne le dict user crÃ©Ã©.
    Utilise RETURNING id â€” jamais result.fetchone() sur execute().
    Constitution Â§9 : crash explicite si INSERT Ã©choue.
    """
    from passlib.context import CryptContext
    pwd_context = CryptContext(schemes=["bcrypt"], deprecated="auto")
    hashed_password = pwd_context.hash(password)

    with get_db_cursor() as cur:
        cur.execute(
            """
            INSERT INTO users
              (username, email, hashed_password, role, created_at)
            VALUES (%s, %s, %s, %s, NOW())
            RETURNING id, username, email, role, created_at
            """,
            (username, email, hashed_password, role),
        )
        # TOUJOURS cur.fetchone() â€” jamais result.fetchone()
        row = cur.fetchone()

    if row is None:
        # Constitution Â§9 : Ã©chec explicite, jamais silencieux
        raise RuntimeError(
            f"create_user : INSERT RETURNING vide pour username={username}. "
            "VÃ©rifier contrainte UNIQUE ou trigger."
        )

    # psycopg RealDictCursor â†’ dict direct
    # psycopg2 tuple â†’ conversion manuelle
    if isinstance(row, dict):
        return dict(row)
    return {
        "id": row[0],
        "username": row[1],
        "email": row[2],
        "role": row[3],
        "created_at": row[4],
    }
2.3 â€” _get_raw_connection inexistant dans src.db
Erreur :


AttributeError: <module 'src.db'> does not have the attribute '_get_raw_connection'
Fix tests/test_resilience.py :


# AVANT (cassÃ© â€” attribut inexistant)
with patch("src.db._get_raw_connection", side_effect=mock_connect):
    ...

# APRÃˆS â€” patcher psycopg2.connect via le module core
from unittest.mock import patch, MagicMock
import psycopg2


def test_retry_db_connection_success_after_failures():
    """
    VÃ©rifie que la connexion DB rÃ©ussit aprÃ¨s N Ã©checs.
    Patche psycopg2.connect Ã  la source.
    """
    call_count = {"n": 0}

    def mock_connect(*args, **kwargs):
        call_count["n"] += 1
        if call_count["n"] < 3:
            raise psycopg2.OperationalError("Connexion refusÃ©e (simulÃ©)")
        return MagicMock()  # succÃ¨s au 3e appel

    with patch("src.db.core.psycopg2.connect", side_effect=mock_connect):
        # RÃ©initialiser le pool pour forcer une nouvelle connexion
        import src.db.core as db_core
        db_core._pool = None
        # Le code de retry doit absorber les 2 premiers Ã©checs
        # et rÃ©ussir au 3e
        # (adapter selon l'implÃ©mentation retry rÃ©elle)


def test_retry_db_fails_after_max_attempts():
    """
    VÃ©rifie que le circuit breaker s'ouvre aprÃ¨s N Ã©checs.
    """
    with patch(
        "src.db.core.psycopg2.connect",
        side_effect=psycopg2.OperationalError("DB morte")
    ):
        import src.db.core as db_core
        db_core._pool = None
        with pytest.raises((psycopg2.OperationalError, Exception)):
            with db_core.get_db_connection():
                pass
2.4 â€” test_inv_04_database_url_required : ne lÃ¨ve pas RuntimeError
Erreur :


Failed: DID NOT RAISE <class 'RuntimeError'>
Cause : src/db/core.py lit DATABASE_URL mais ne lÃ¨ve pas d'exception si absent â€” il retourne None silencieusement.

Fix src/db/core.py :


import os
import sys

def _get_database_url() -> str:
    """
    Lit DATABASE_URL depuis l'environnement.
    Crash explicite si absent. Constitution Â§9.
    """
    url = os.environ.get("DATABASE_URL")
    if not url:
        print(
            "FATAL: DATABASE_URL non dÃ©fini. "
            "PostgreSQL requis â€” ADR-0001 INV-4.",
            file=sys.stderr,
        )
        raise RuntimeError(
            "DATABASE_URL manquant. "
            "DÃ©finir via variable d'environnement."
        )
    if "sqlite" in url.lower():
        raise RuntimeError(
            "SQLite interdit â€” ADR-0001 INV-4. "
            "Utiliser PostgreSQL uniquement."
        )
    return url

DATABASE_URL: str = _get_database_url()
2.5 â€” _store_extraction : signature incompatible avec le test
Erreur :


TypeError: fake_store_extraction() got an unexpected keyword argument 'case_id'
Cause : Le test mocke _store_extraction sans le paramÃ¨tre case_id ajoutÃ© par ADR-0004.

Fix tests/phase0/test_extraction_service.py :


# Mettre Ã  jour la signature du fake dans le test

def fake_store_extraction(
    document_id: str,
    raw_text: str,
    structured_data: dict,
    method: str,
    confidence: float,
    duration_ms: float,
    case_id: str | None = None,  # â† ajouter ce paramÃ¨tre
) -> None:
    store_calls.append({
        "document_id": document_id,
        "confidence": confidence,
        "method": method,
        "case_id": case_id,
    })
3. CORRECTION C1 â€” Append-only cohÃ©rent : score_runs
3.1 Migration dÃ©diÃ©e

-- alembic/versions/014_m_score_runs_appendonly.py

def upgrade() -> None:
    # 1. Supprimer supplier_scores si elle existe (incompatible append-only)
    op.execute("DROP TABLE IF EXISTS supplier_scores CASCADE")

    # 2. CrÃ©er score_runs (Ã©vÃ©nements immuables)
    op.execute("""
        CREATE TABLE score_runs (
            id                  UUID PRIMARY KEY DEFAULT gen_random_uuid(),
            batch_id            UUID NOT NULL,
            case_id             UUID NOT NULL,
            supplier_id         UUID NOT NULL,
            run_at              TIMESTAMP NOT NULL DEFAULT NOW(),
            calculated_by       UUID NOT NULL,
            profile_used        VARCHAR(50) NOT NULL,
            total_score         NUMERIC(5,2) NOT NULL
                                CHECK (total_score BETWEEN 0 AND 100),
            is_eliminated       BOOLEAN NOT NULL DEFAULT FALSE,
            elimination_reason  TEXT,
            score_detail        JSONB NOT NULL DEFAULT '{}'::jsonb,
            trigger_event       VARCHAR(100) NOT NULL DEFAULT 'manual'
        )
    """)

    # 3. Index performance
    op.execute("""
        CREATE INDEX ix_score_runs_case_supplier_runat
        ON score_runs (case_id, supplier_id, run_at DESC, id DESC)
    """)
    op.execute("""
        CREATE INDEX ix_score_runs_batch_id
        ON score_runs (batch_id, run_at DESC)
    """)

    # 4. Vue "Ã©tat courant" â€” dernier run par fournisseur par case
    op.execute("""
        CREATE VIEW current_supplier_scores AS
        SELECT DISTINCT ON (case_id, supplier_id)
            id, batch_id, case_id, supplier_id,
            run_at, calculated_by, profile_used,
            total_score, is_eliminated,
            elimination_reason, score_detail, trigger_event
        FROM score_runs
        ORDER BY case_id, supplier_id, run_at DESC, id DESC
    """)

    # 5. Trigger append-only
    op.execute("""
        CREATE OR REPLACE FUNCTION enforce_append_only_score_runs()
        RETURNS TRIGGER AS $$
        BEGIN
            RAISE EXCEPTION
                'VIOLATION APPEND-ONLY : score_runs est immuable. '
                'CrÃ©er un nouveau score_run. '
                'Constitution V3.3.2 INV-9.';
        END;
        $$ LANGUAGE plpgsql
    """)
    op.execute("""
        CREATE TRIGGER trigger_append_only_score_runs
        BEFORE UPDATE OR DELETE ON score_runs
        FOR EACH ROW
        EXECUTE FUNCTION enforce_append_only_score_runs()
    """)


def downgrade() -> None:
    op.execute("DROP VIEW IF EXISTS current_supplier_scores")
    op.execute(
        "DROP TRIGGER IF EXISTS trigger_append_only_score_runs ON score_runs"
    )
    op.execute(
        "DROP FUNCTION IF EXISTS enforce_append_only_score_runs()"
    )
    op.execute("DROP TABLE IF EXISTS score_runs CASCADE")
3.2 Code API scoring â€” INSERT ONLY + batch_id

# src/couche_a/scoring/api.py
from uuid import uuid4
from src.db.core import get_db_cursor
from src.auth import get_current_user, User
from fastapi import Depends, HTTPException
import logging

logger = logging.getLogger(__name__)


@router.post("/api/scoring/calculate")
def calculate_scoring(
    case_id: str,
    current_user: User = Depends(get_current_user),
):
    """
    Calcule le scoring d'un case.
    Append-only : chaque exÃ©cution crÃ©e un nouveau batch dans score_runs.
    La vue current_supplier_scores expose le dernier Ã©tat.
    """
    batch_id = str(uuid4())

    # 1. Charger suppliers + criteria (inchangÃ© depuis ADR-0004)
    # ... (chargement depuis DB)

    # 2. Calculer avec le moteur
    # ... (ScoringEngine.calculate())

    # 3. Persister â€” INSERT ONLY â€” jamais UPSERT
    scores_count = 0
    eliminations_count = 0

    with get_db_cursor() as cur:
        for result in results:
            cur.execute(
                """
                INSERT INTO score_runs
                  (batch_id, case_id, supplier_id, calculated_by,
                   profile_used, total_score, is_eliminated,
                   elimination_reason, score_detail, trigger_event)
                VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s)
                """,
                (
                    batch_id,
                    case_id,
                    result.supplier_id,
                    str(current_user.id),
                    profile.value,
                    result.total_score,
                    result.is_eliminated,
                    result.elimination_reason,
                    result.score_detail,
                    "manual",
                ),
            )
            scores_count += 1
            if result.is_eliminated:
                eliminations_count += 1

    # 4. Lire le classement courant depuis la VUE
    with get_db_cursor() as cur:
        cur.execute(
            """
            SELECT supplier_id, total_score, is_eliminated,
                   profile_used, run_at
            FROM current_supplier_scores
            WHERE case_id = %s
            ORDER BY total_score DESC NULLS LAST
            """,
            (case_id,),
        )
        current_scores = cur.fetchall()

    logger.info(
        "Scoring batch=%s case=%s : %d scores, %d Ã©liminations",
        batch_id, case_id, scores_count, eliminations_count,
    )

    return {
        "case_id": case_id,
        "batch_id": batch_id,
        "scores_count": scores_count,
        "eliminations_count": eliminations_count,
        "profile_used": profile.value,
        "current_ranking": [dict(r) for r in current_scores],
    }
3.3 Gate CI bloquant

# tests/invariants/test_no_upsert_on_immutable_tables.py
import pathlib

IMMUTABLE_TABLES = {
    "score_runs", "cases", "documents", "artifacts",
    "extractions", "extraction_errors", "offers", "audit_log",
}


def test_no_upsert_on_immutable_tables():
    """
    VÃ©rifie l'absence d'ON CONFLICT DO UPDATE
    sur toutes les tables append-only.
    Constitution V3.3.2 INV-9.
    """
    violations = []
    for py_file in pathlib.Path("src").rglob("*.py"):
        source = py_file.read_text(errors="ignore")
        upper = source.upper()
        if "ON CONFLICT" not in upper or "DO UPDATE" not in upper:
            continue
        lower = source.lower()
        for table in IMMUTABLE_TABLES:
            if table in lower:
                violations.append(
                    f"{py_file} â€” UPSERT interdit sur '{table}'"
                )

    assert not violations, (
        "VIOLATION C1 â€” UPSERT sur table append-only :\n"
        + "\n".join(violations)
    )
4. CORRECTION C2 â€” Extraction : retour typÃ©
4.1 Types canoniques

# src/couche_a/extraction.py

from __future__ import annotations
from dataclasses import dataclass
from enum import Enum


class ExtractionStatus(str, Enum):
    SUCCESS     = "success"      # donnÃ©es extraites, confiance >= 0.6
    EMPTY       = "empty"        # extraction ok mais 0 critÃ¨re trouvÃ©
    FAILED      = "failed"       # erreur technique
    UNSUPPORTED = "unsupported"  # format non supportÃ©
    DEGRADED    = "degraded"     # partiel, confiance < 0.6


@dataclass(frozen=True)
class ExtractionResult:
    status:        ExtractionStatus
    data:          list[dict]       # toujours [] si status != SUCCESS/DEGRADED
    confidence:    float            # 0.0 si FAILED
    error_code:    str | None       # ex: "FILE_NOT_FOUND", "PARSE_ERROR"
    error_message: str | None       # lisible par l'utilisateur
    items_found:   int              # 0 si EMPTY ou FAILED
    method_used:   str | None       # "native_pdf", "ocr", "xlsx", etc.
4.2 Fonction canonique

def extract_dao_criteria_structured(document_id: str) -> ExtractionResult:
    """
    Retourne TOUJOURS un ExtractionResult typÃ©.
    Jamais de [] nu. Constitution Â§9 : Ã©chec explicite.

    Mapping statuts â†’ codes HTTP (gÃ©rÃ© par l'endpoint) :
      FAILED      â†’ 422 avec error_code + message
      EMPTY       â†’ 200 avec message explicite
      SUCCESS     â†’ 200 avec data + confidence
      DEGRADED    â†’ 200 avec data + warning confidence faible
      UNSUPPORTED â†’ 422 avec error_code FORMAT_NOT_SUPPORTED
    """
    import logging
    logger = logging.getLogger(__name__)

    # 1. Chercher le document
    with get_db_cursor() as cur:
        cur.execute(
            """
            SELECT d.id, d.storage_uri, d.mime_type,
                   e.structured_data, e.confidence_score,
                   e.extraction_method
            FROM documents d
            LEFT JOIN extractions e ON e.document_id = d.id
            WHERE d.id = %s
            ORDER BY e.extracted_at DESC NULLS LAST
            LIMIT 1
            """,
            (document_id,),
        )
        row = cur.fetchone()

    if not row:
        return ExtractionResult(
            status=ExtractionStatus.FAILED,
            data=[],
            confidence=0.0,
            error_code="DOCUMENT_NOT_FOUND",
            error_message=f"Document {document_id} introuvable",
            items_found=0,
            method_used=None,
        )

    # 2. Extraction dÃ©jÃ  disponible avec confiance suffisante
    confidence = float(row.get("confidence_score") or 0)
    if row.get("structured_data") and confidence >= 0.6:
        criteria = _extract_criteria_from_structured(row["structured_data"])
        status = ExtractionStatus.SUCCESS if criteria else ExtractionStatus.EMPTY
        return ExtractionResult(
            status=status,
            data=criteria,
            confidence=confidence,
            error_code=None,
            error_message=None,
            items_found=len(criteria),
            method_used=row.get("extraction_method"),
        )

    # 3. Pas de fichier stockÃ©
    if not row.get("storage_uri"):
        return ExtractionResult(
            status=ExtractionStatus.FAILED,
            data=[],
            confidence=0.0,
            error_code="NO_STORAGE_URI",
            error_message="Fichier physique non disponible",
            items_found=0,
            method_used=None,
        )

    # 4. Extraire fraÃ®chement
    try:
        structured_data, method, fresh_confidence = _run_extraction(
            storage_uri=row["storage_uri"],
            mime_type=row.get("mime_type"),
        )
    except FileNotFoundError as exc:
        return ExtractionResult(
            status=ExtractionStatus.FAILED,
            data=[],
            confidence=0.0,
            error_code="FILE_NOT_FOUND",
            error_message=str(exc),
            items_found=0,
            method_used=None,
        )
    except ValueError as exc:
        return ExtractionResult(
            status=ExtractionStatus.UNSUPPORTED,
            data=[],
            confidence=0.0,
            error_code="FORMAT_NOT_SUPPORTED",
            error_message=str(exc),
            items_found=0,
            method_used=None,
        )
    except Exception as exc:
        logger.error(
            "Extraction Ã©chouÃ©e document=%s : %s", document_id, exc
        )
        return ExtractionResult(
            status=ExtractionStatus.FAILED,
            data=[],
            confidence=0.0,
            error_code="EXTRACTION_ERROR",
            error_message=str(exc),
            items_found=0,
            method_used=None,
        )

    criteria = _extract_criteria_from_structured(structured_data)

    if not criteria:
        return ExtractionResult(
            status=ExtractionStatus.EMPTY,
            data=[],
            confidence=fresh_confidence,
            error_code=None,
            error_message=None,
            items_found=0,
            method_used=method,
        )

    status = (
        ExtractionStatus.DEGRADED
        if fresh_confidence < 0.6
        else ExtractionStatus.SUCCESS
    )

    return ExtractionResult(
        status=status,
        data=criteria,
        confidence=fresh_confidence,
        error_code=None,
        error_message=(
            f"Confiance faible ({fresh_confidence:.0%}) â€” vÃ©rification conseillÃ©e"
            if status == ExtractionStatus.DEGRADED
            else None
        ),
        items_found=len(criteria),
        method_used=method,
    )
4.3 Endpoint qui consomme le rÃ©sultat

# src/api/analysis.py

from fastapi.responses import JSONResponse


@router.post("/api/cases/{case_id}/extract-criteria")
def extract_criteria(
    case_id: str,
    document_id: str,
    current_user: User = Depends(get_current_user),
):
    result = extract_dao_criteria_structured(document_id)

    if result.status == ExtractionStatus.FAILED:
        raise HTTPException(
            status_code=422,
            detail={
                "error_code": result.error_code,
                "message": result.error_message,
                "criteria": [],
            },
        )

    if result.status == ExtractionStatus.UNSUPPORTED:
        raise HTTPException(
            status_code=422,
            detail={
                "error_code": "FORMAT_NOT_SUPPORTED",
                "message": result.error_message,
                "criteria": [],
            },
        )

    if result.status == ExtractionStatus.EMPTY:
        return JSONResponse(
            status_code=200,
            content={
                "status": "empty",
                "message": (
                    "Aucun critÃ¨re dÃ©tectÃ© automatiquement. "
                    "Saisie manuelle disponible."
                ),
                "criteria": [],
                "confidence": result.confidence,
            },
        )

    # SUCCESS ou DEGRADED
    return {
        "status": result.status.value,
        "criteria": result.data,
        "confidence": result.confidence,
        "items_found": result.items_found,
        "method_used": result.method_used,
        "warning": result.error_message,
    }
4.4 Gate CI

# tests/invariants/test_extraction_result_typed.py
import inspect
from src.couche_a.extraction import (
    extract_dao_criteria_structured,
    ExtractionResult,
)


def test_extract_dao_return_type_is_structured():
    """
    VÃ©rifie que extract_dao_criteria_structured()
    est annotÃ© ExtractionResult â€” jamais list.
    Constitution Â§9 : retour ambigu interdit.
    """
    sig = inspect.signature(extract_dao_criteria_structured)
    assert sig.return_annotation == ExtractionResult, (
        f"VIOLATION C2 : return_annotation attendu ExtractionResult, "
        f"trouvÃ© {sig.return_annotation}. "
        f"Le stub return [] est interdit."
    )
5. CORRECTION C3+C4 â€” Dictionnaire Sahel : seeds vÃ©rifiÃ©s
5.1 SchÃ©ma enrichi

-- Dans la migration 015_m_procurement_dictionary.py

CREATE TABLE procurement_dictionary (
    id               SERIAL PRIMARY KEY,
    famille          VARCHAR(100) NOT NULL,
    label_canonical  VARCHAR(200) NOT NULL UNIQUE,
    code_mercuriale  VARCHAR(50) NOT NULL,
    unite_canonical  VARCHAR(50) NOT NULL,
    prix_min_xof     INTEGER NOT NULL CHECK (prix_min_xof > 0),
    prix_moyen_xof   INTEGER NOT NULL CHECK (prix_moyen_xof > 0),
    prix_max_xof     INTEGER NOT NULL CHECK (prix_max_xof > 0),
    -- Contrainte cohÃ©rence prix â€” RÃˆGLE MERCURIALE-001
    CHECK (prix_min_xof <= prix_moyen_xof),
    CHECK (prix_moyen_xof <= prix_max_xof),
    annee_mercuriale INTEGER NOT NULL DEFAULT 2023,
    zone             VARCHAR(100) NOT NULL DEFAULT 'bamako',
    source_pdf       VARCHAR(200) NOT NULL,
    source_page      INTEGER NOT NULL,  -- obligatoire
    created_at       TIMESTAMP DEFAULT NOW()
);

CREATE TABLE dict_aliases (
    id       SERIAL PRIMARY KEY,
    dict_id  INTEGER NOT NULL REFERENCES procurement_dictionary(id),
    alias    VARCHAR(200) NOT NULL,
    UNIQUE (dict_id, alias)
);

CREATE INDEX ix_dict_label ON procurement_dictionary
    USING gin (to_tsvector('french', label_canonical));
CREATE INDEX ix_dict_aliases ON dict_aliases
    USING gin (to_tsvector('french', alias));
5.2 Validator canonique

# src/couche_b/mercuriale_validator.py

from dataclasses import dataclass


@dataclass
class MercurialeEntry:
    code: str
    famille: str
    label_canonical: str
    unite: str
    prix_min: int
    prix_moyen: int
    prix_max: int
    annee: int
    zone: str
    source_pdf: str
    source_page: int


class MercurialeValidator:
    """
    Valide chaque entrÃ©e avant insertion.
    RÃˆGLE MERCURIALE-001 : zÃ©ro tolÃ©rance sur les incohÃ©rences.
    """

    def validate(self, entry: MercurialeEntry) -> list[str]:
        errors = []

        # CohÃ©rence prix
        if not (entry.prix_min <= entry.prix_moyen <= entry.prix_max):
            errors.append(
                f"Prix incohÃ©rents : {entry.prix_min} â‰¤ "
                f"{entry.prix_moyen} â‰¤ {entry.prix_max} â€” FAUX"
            )
        if entry.prix_min <= 0:
            errors.append("prix_min doit Ãªtre > 0")

        # Champs obligatoires non vides
        required = {
            "label_canonical": entry.label_canonical,
            "unite": entry.unite,
            "code": entry.code,
            "source_pdf": entry.source_pdf,
            "zone": entry.zone,
        }
        for field, value in required.items():
            if not value or not str(value).strip():
                errors.append(f"'{field}' ne peut pas Ãªtre vide")

        # source_page obligatoire
        if entry.source_page is None or entry.source_page <= 0:
            errors.append(
                "source_page obligatoire et > 0 "
                "(numÃ©ro de page dans le PDF source)"
            )

        # AnnÃ©e plausible
        if not (2020 <= entry.annee <= 2030):
            errors.append(
                f"annee_mercuriale={entry.annee} hors plage 2020â€“2030"
            )

        return errors

    def validate_batch(
        self, entries: list[MercurialeEntry]
    ) -> dict[str, list[str]]:
        return {
            e.label_canonical: errs
            for e in entries
            if (errs := self.validate(e))
        }
5.3 Seeds MVP â€” vÃ©rifiÃ©s sur PDF Bamako 2023
Tous les items ci-dessous ont Ã©tÃ© vÃ©rifiÃ©s sur Bulletin_Result_Bko2023.pdf.
Format : (famille, label_canonical, code, unite, min, moyen, max, page)


-- Migration seed (extrait â€” 015_m_procurement_dictionary.py)

INSERT INTO procurement_dictionary
  (famille, label_canonical, code_mercuriale, unite_canonical,
   prix_min_xof, prix_moyen_xof, prix_max_xof,
   annee_mercuriale, zone, source_pdf, source_page)
VALUES

-- â”€â”€ CARBURANTS (Groupe 5.4.1, page 120) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
('carburants', 'Essence super',  '5.4.1.1', 'Litre',  881,    882,    889,    2023, 'bamako', 'Bulletin_Result_Bko2023.pdf', 120),
('carburants', 'Gasoil',         '5.4.1.2', 'Litre',  801,    853,    879,    2023, 'bamako', 'Bulletin_Result_Bko2023.pdf', 120),
('carburants', 'PÃ©trole',        '5.4.1.3', 'Litre',  755,    778,    800,    2023, 'bamako', 'Bulletin_Result_Bko2023.pdf', 120),

-- Gaz butane (page 56) â€” contenant vide uniquement
('carburants', 'Gaz butane 6Kg bouteille vide', '3.3', 'UnitÃ©', 17500, 21250, 25000, 2023, 'bamako', 'Bulletin_Result_Bko2023.pdf', 56),

-- â”€â”€ FOURNITURES BUREAU (Groupe 1.1) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
('fournitures_bureau', 'Rame papier A4 80g',            '1.1.228', 'Rame',       5000,  5333,  6000,  2023, 'bamako', 'Bulletin_Result_Bko2023.pdf', 8),
('fournitures_bureau', 'Chemises ordinaires',           '1.1.115', 'Paquet/100', 3500,  4100,  6000,  2023, 'bamako', 'Bulletin_Result_Bko2023.pdf', 5),
('fournitures_bureau', 'Agrafeuse MF',                  '1.1.27',  'UnitÃ©',      7500,  8200,  9000,  2023, 'bamako', 'Bulletin_Result_Bko2023.pdf', 3),
('fournitures_bureau', 'Trombones MF',                  '1.1.286', 'Paquet/100', 2000,  2500,  3000,  2023, 'bamako', 'Bulletin_Result_Bko2023.pdf', 10),
('fournitures_bureau', 'Registre GF',                   '1.1.255', 'UnitÃ©',      10000, 12500, 15000, 2023, 'bamako', 'Bulletin_Result_Bko2023.pdf', 9),
('fournitures_bureau', 'Scotch emballage transparent',  '1.1.270', 'UnitÃ©',      1000,  1250,  1500,  2023, 'bamako', 'Bulletin_Result_Bko2023.pdf', 9),
('fournitures_bureau', 'Stylo Bic bleu cristal',        '1.4.3',   'Paquet/50',  3500,  4000,  5000,  2023, 'bamako', 'Bulletin_Result_Bko2023.pdf', 21),

-- â”€â”€ INFORMATIQUE (Groupe 1.3) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
('informatique', 'ClÃ© USB 8 GB',              '1.3.104', 'UnitÃ©', 3500,  4375,  5000,  2023, 'bamako', 'Bulletin_Result_Bko2023.pdf', 15),
('informatique', 'ClÃ© USB 16 GB',             '1.3.94',  'UnitÃ©', 3000,  3250,  3500,  2023, 'bamako', 'Bulletin_Result_Bko2023.pdf', 14),
('informatique', 'ClÃ© USB 32 GB',             '1.3.101', 'UnitÃ©', 5000,  5500,  6000,  2023, 'bamako', 'Bulletin_Result_Bko2023.pdf', 15),
('informatique', 'Disque dur externe 1 To',   '1.3.115', 'UnitÃ©', 45000, 47500, 50000, 2023, 'bamako', 'Bulletin_Result_Bko2023.pdf', 15),
('informatique', 'Barrette mÃ©moire DDR 4GB',  '1.3.12',  'UnitÃ©', 35000, 40000, 45000, 2023, 'bamako', 'Bulletin_Result_Bko2023.pdf', 13),

-- â”€â”€ CONSTRUCTION LIANTS (Groupe 2.1) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
('construction_liants', 'Ciment CPA 42.5',    '2.1.5', 'Tonne', 100000, 107000, 115000, 2023, 'bamako', 'Bulletin_Result_Bko2023.pdf', 29),
('construction_liants', 'Ciment CPA 45',      '2.1.1', 'Tonne', 110000, 124000, 140000, 2023, 'bamako', 'Bulletin_Result_Bko2023.pdf', 29),
('construction_liants', 'Ciment CPA 52.5',    '2.1.4', 'Tonne', 115000, 133000, 150000, 2023, 'bamako', 'Bulletin_Result_Bko2023.pdf', 29),
('construction_liants', 'Ciment M 32.5',      '2.1.6', 'Tonne', 100000, 105000, 107500, 2023, 'bamako', 'Bulletin_Result_Bko2023.pdf', 29),

-- â”€â”€ CONSTRUCTION AGRÃ‰GATS (Groupe 2.2) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
('construction_agregats', 'Sable fleuve voyage 7m3',    '2.2.9',  'Voyage 7m3', 70000, 75000, 80000, 2023, 'bamako', 'Bulletin_Result_Bko2023.pdf', 30),
('construction_agregats', 'Gravier concassÃ© 15/25 7m3', '2.2.2',  'Voyage 7m3', 60000, 70000, 75000, 2023, 'bamako', 'Bulletin_Result_Bko2023.pdf', 30),
('construction_agregats', 'Gravillon 6/10 7m3',         '2.2.6',  'Voyage 7m3', 140000,145000,150000,2023,'bamako', 'Bulletin_Result_Bko2023.pdf', 30),
('construction_agregats', 'LatÃ©rite voyage 7m3',        '2.2.17', 'Voyage 7m3', 30000, 33333, 35000, 2023, 'bamako', 'Bulletin_Result_Bko2023.pdf', 30),

-- â”€â”€ CONSTRUCTION FER (Groupe 2.4) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
('construction_fer', 'Rond tor HA10 barre 12m', '2.4.18', 'Barre', 2500,  3350,  4000,  2023, 'bamako', 'Bulletin_Result_Bko2023.pdf', 31),
('construction_fer', 'Rond tor HA12 barre 12m', '2.4.19', 'Barre', 3100,  3525,  4500,  2023, 'bamako', 'Bulletin_Result_Bko2023.pdf', 31),
('construction_fer', 'Rond tor HA16 barre 12m', '2.4.21', 'Barre', 12500, 16100, 20000, 2023, 'bamako', 'Bulletin_Result_Bko2023.pdf', 31),
('construction_fer', 'TÃ´le ondulÃ©e 6kg',        '2.6.11', 'Feuille',5000, 5700,  6500,  2023, 'bamako', 'Bulletin_Result_Bko2023.pdf', 33),

-- â”€â”€ MÃ‰DICAMENTS (Groupe 7.1) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
('medicaments', 'Amoxicilline Tong 500mg Cp boite 12',   '7.1.152',  'Boite 12', 860,  860,  860,  2023, 'bamako', 'Bulletin_Result_Bko2023.pdf', 131),
('medicaments', 'Coartem 20/120mg Comp 4x6',             '7.1.640',  'Boite 24', 3945, 4158, 4570, 2023, 'bamako', 'Bulletin_Result_Bko2023.pdf', 139),
('medicaments', 'Coartesiane susp 60ml',                  '7.1.644',  'Flacon',   2350, 2461, 2480, 2023, 'bamako', 'Bulletin_Result_Bko2023.pdf', 139),
('medicaments', 'Metronidazole Tong 500mg Cp boite 20',  '7.1.1611', 'Boite 20', 800,  800,  800,  2023, 'bamako', 'Bulletin_Result_Bko2023.pdf', 153),
('medicaments', 'Paracetamol 500 Cp Pl12 boite 24',      '7.1.1825', 'Boite 24', 100,  100,  100,  2023, 'bamako', 'Bulletin_Result_Bko2023.pdf', 157),

-- â”€â”€ VÃ‰HICULES (Groupe 5.5) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
('vehicules', 'Toyota Hilux DC 4x4 diesel Standard', '5.5.v1', 'UnitÃ©', 24700000, 24700000, 24700000, 2023, 'bamako', 'Bulletin_Result_Bko2023.pdf', 120),
('vehicules', 'Toyota Land Cruiser 78 Hard Top',      '5.5.v2', 'UnitÃ©', 34400000, 34400000, 34400000, 2023, 'bamako', 'Bulletin_Result_Bko2023.pdf', 120),

-- â”€â”€ Ã‰QUIPEMENTS (Groupe 8) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
('equipements', 'Climatiseur split 1.5 CV',          '8.1.121', 'UnitÃ©', 180000,  195000,  215000,  2023, 'bamako', 'Bulletin_Result_Bko2023.pdf', 183),
('equipements', 'Groupe Ã©lectrogÃ¨ne 10 KVA SDMO',    '8.8.21',  'UnitÃ©', 3650000, 4737500, 5300000, 2023, 'bamako', 'Bulletin_Result_Bko2023.pdf', 200),
('equipements', 'Photocopieuse Canon IR 2520',       '8.3.23',  'UnitÃ©', 400000,  467500,  550000,  2023, 'bamako', 'Bulletin_Result_Bko2023.pdf', 191),
('equipements', 'Imprimante HP Laserjet M 107 W',    '8.4.52',  'UnitÃ©', 140000,  150000,  160000,  2023, 'bamako', 'Bulletin_Result_Bko2023.pdf', 198),
('equipements', 'Imprimante HP Laserjet 107 W',      '8.4.53',  'UnitÃ©', 140000,  152500,  165000,  2023, 'bamako', 'Bulletin_Result_Bko2023.pdf', 198)

ON CONFLICT (label_canonical) DO NOTHING;
5.4 Aliases canoniques

INSERT INTO dict_aliases (dict_id, alias) VALUES
  -- Gasoil
  ((SELECT id FROM procurement_dictionary WHERE label_canonical = 'Gasoil'), 'Gas oil'),
  ((SELECT id FROM procurement_dictionary WHERE label_canonical = 'Gasoil'), 'GasoÃ¯l'),
  ((SELECT id FROM procurement_dictionary WHERE label_canonical = 'Gasoil'), 'Diesel'),
  ((SELECT id FROM procurement_dictionary WHERE label_canonical = 'Gasoil'), 'GO'),
  -- Ciment CPA 42.5
  ((SELECT id FROM procurement_dictionary WHERE label_canonical = 'Ciment CPA 42.5'), 'Ciment Portland CPA 42,5'),
  ((SELECT id FROM procurement_dictionary WHERE label_canonical = 'Ciment CPA 42.5'), 'CPA 42.5'),
  ((SELECT id FROM procurement_dictionary WHERE label_canonical = 'Ciment CPA 42.5'), 'Ciment CPA-42.5'),
  -- Rond HA10
  ((SELECT id FROM procurement_dictionary WHERE label_canonical = 'Rond tor HA10 barre 12m'), 'Fer Ã  bÃ©ton HA 10'),
  ((SELECT id FROM procurement_dictionary WHERE label_canonical = 'Rond tor HA10 barre 12m'), 'Acier HA10'),
  ((SELECT id FROM procurement_dictionary WHERE label_canonical = 'Rond tor HA10 barre 12m'), 'Rond HA10'),
  -- Gaz butane
  ((SELECT id FROM procurement_dictionary WHERE label_canonical = 'Gaz butane 6Kg bouteille vide'), 'Bouteille gaz 6kg (vide)'),
  ((SELECT id FROM procurement_dictionary WHERE label_canonical = 'Gaz butane 6Kg bouteille vide'), 'Contenant gaz butane 6kg'),
  -- Rame papier
  ((SELECT id FROM procurement_dictionary WHERE label_canonical = 'Rame papier A4 80g'), 'Papier A4 500 feuilles'),
  ((SELECT id FROM procurement_dictionary WHERE label_canonical = 'Rame papier A4 80g'), 'Rame A4 80gr'),
  ((SELECT id FROM procurement_dictionary WHERE label_canonical = 'Rame papier A4 80g'), 'Papier photocopie A4')
ON CONFLICT (dict_id, alias) DO NOTHING;
5.5 Gates CI intÃ©gritÃ© mercuriale

# tests/db_integrity/test_mercuriale_seed_integrity.py


def test_mercuriale_seed_prix_coherence(db_conn):
    """
    VÃ©rifie prix_min <= prix_moyen <= prix_max sur tous les items.
    RÃˆGLE MERCURIALE-001.
    """
    with db_conn.cursor() as cur:
        cur.execute("""
            SELECT label_canonical, prix_min_xof,
                   prix_moyen_xof, prix_max_xof
            FROM procurement_dictionary
            WHERE NOT (
                prix_min_xof <= prix_moyen_xof
                AND prix_moyen_xof <= prix_max_xof
            )
        """)
        violations = cur.fetchall()

    assert not violations, (
        "VIOLATION C4 â€” Prix incohÃ©rents :\n"
        + "\n".join(
            f"  {v['label_canonical']}: "
            f"{v['prix_min_xof']} / {v['prix_moyen_xof']} / {v['prix_max_xof']}"
            for v in violations
        )
    )


def test_mercuriale_seed_no_null_units(db_conn):
    with db_conn.cursor() as cur:
        cur.execute("""
            SELECT label_canonical FROM procurement_dictionary
            WHERE unite_canonical IS NULL
               OR trim(unite_canonical) = ''
        """)
        violations = cur.fetchall()

    assert not violations, (
        "VIOLATION C4 â€” UnitÃ©s manquantes :\n"
        + "\n".join(v["label_canonical"] for v in violations)
    )


def test_mercuriale_seed_source_page_required(db_conn):
    """
    source_page obligatoire â€” RÃˆGLE MERCURIALE-001.
    """
    with db_conn.cursor() as cur:
        cur.execute("""
            SELECT label_canonical FROM procurement_dictionary
            WHERE source_page IS NULL OR source_page <= 0
        """)
        violations = cur.fetchall()

    assert not violations, (
        "VIOLATION MERCURIALE-001 â€” source_page manquante :\n"
        + "\n".join(v["label_canonical"] for v in violations)
    )
6. Tous les gates CI â€” registre complet

REGISTRE GATES ADR-0005 FROZEN â€” TOUS BLOQUANTS ðŸ”´

DÃ‰BLOCAGE PR #85 :
  ðŸ”´ test_inv_04_database_url_required     (corrigÃ© src/db/core.py)
  ðŸ”´ test_register_user                    (corrigÃ© create_user RETURNING)
  ðŸ”´ test_retry_db_connection_*            (corrigÃ© mock psycopg2.connect)
  ðŸ”´ Migrations avant pytest               (corrigÃ© CI + conftest)

C1 â€” APPEND-ONLY :
  ðŸ”´ test_no_upsert_on_immutable_tables

C2 â€” EXTRACTION TYPÃ‰E :
  ðŸ”´ test_extract_dao_return_type_is_structured

C4 â€” MERCURIALE INTÃ‰GRITÃ‰ :
  ðŸ”´ test_mercuriale_seed_prix_coherence
  ðŸ”´ test_mercuriale_seed_no_null_units
  ðŸ”´ test_mercuriale_seed_source_page_required

TOTAL ADR-0005 : 9 gates
TOTAL CUMULÃ‰ (ADR-0001 â†’ ADR-0005) : 47 gates bloquants
7. SÃ©quence d'exÃ©cution pour l'agent â€” ordre strict

# â”€â”€â”€ PHASE 1 : DÃ‰BLOCAGE IMMÃ‰DIAT PR #85 â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

# Fix 1 â€” create_user RETURNING id
# Modifier src/auth.py lignes autour de la ligne 234

# Fix 2 â€” DATABASE_URL crash explicite
# Modifier src/db/core.py â€” ajouter _get_database_url()

# Fix 3 â€” Mock rÃ©silience : patcher psycopg2.connect
# Modifier tests/test_resilience.py

# Fix 4 â€” Signature _store_extraction avec case_id
# Modifier tests/phase0/test_extraction_service.py

# Fix 5 â€” conftest intÃ©gration : migrations auto-run
# Modifier tests/integration/conftest.py

# Fix 6 â€” CI workflow : alembic upgrade head avant pytest
# Modifier .github/workflows/ci_main.yml

git add src/auth.py src/db/core.py \
        tests/test_resilience.py \
        tests/phase0/test_extraction_service.py \
        tests/integration/conftest.py \
        .github/workflows/ci_main.yml

git commit -m "fix(PR85): migrations avant tests + create_user RETURNING + mock psycopg2 + DATABASE_URL crash"

# â”€â”€â”€ PHASE 2 : APPEND-ONLY SCORING â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

# CrÃ©er alembic/versions/014_m_score_runs_appendonly.py (Â§3.1)
# Modifier src/couche_a/scoring/api.py (Â§3.2)
# CrÃ©er tests/invariants/test_no_upsert_on_immutable_tables.py (Â§3.3)

alembic upgrade head

git add alembic/versions/014_m_score_runs_appendonly.py \
        src/couche_a/scoring/api.py \
        tests/invariants/test_no_upsert_on_immutable_tables.py

git commit -m "feat(M-SECURITY): score_runs append-only + batch_id + vue current_supplier_scores (C1)"

# â”€â”€â”€ PHASE 3 : EXTRACTION TYPÃ‰E â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

# Modifier src/couche_a/extraction.py (Â§4.1 + Â§4.2)
# Modifier src/api/analysis.py (Â§4.3)
# CrÃ©er tests/invariants/test_extraction_result_typed.py (Â§4.4)

git add src/couche_a/extraction.py \
        src/api/analysis.py \
        tests/invariants/test_extraction_result_typed.py

git commit -m "feat(M-DAO-EXTRACTION-FIX): ExtractionResult typÃ© â€” fin du return [] ambigu (C2)"

# â”€â”€â”€ PHASE 4 : DICTIONNAIRE SAHEL â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

# CrÃ©er alembic/versions/015_m_procurement_dictionary.py (Â§5.1 + Â§5.3 + Â§5.4)
# CrÃ©er src/couche_b/mercuriale_validator.py (Â§5.2)
# CrÃ©er tests/db_integrity/test_mercuriale_seed_integrity.py (Â§5.5)

alembic upgrade head

git add alembic/versions/015_m_procurement_dictionary.py \
        src/couche_b/mercuriale_validator.py \
        tests/db_integrity/test_mercuriale_seed_integrity.py

git commit -m "feat(M-DICT-SAHEL): dictionnaire Sahel MVP vÃ©rifiÃ©s PDF + validator + gates CI (C3/C4)"

# â”€â”€â”€ PHASE 5 : VÃ‰RIFICATION FINALE â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

pytest tests/ -x -q
# Attendu : 0 failed

git push origin feat/M-EXTRACTION-ENGINE

# Convertir Draft â†’ Ready for review sur GitHub
# Merge PR #85
# touch .milestones/M-EXTRACTION-ENGINE.done
# git commit -m "milestone(M-EXTRACTION-ENGINE): DONE"
8. RÃ¨gle MERCURIALE-001 â€” Opposable

RÃˆGLE MERCURIALE-001 (ADR-0005 Â§8 â€” FROZEN â€” opposable tout agent)

Toute valeur insÃ©rÃ©e dans procurement_dictionary DOIT :

  1. code_mercuriale exact (ex: 5.4.1.2 â€” pas 3.3.2)
  2. source_page > 0 (numÃ©ro de page dans le PDF source)
  3. source_pdf non vide (nom du fichier PDF de rÃ©fÃ©rence)
  4. passer MercurialeValidator.validate() â†’ liste vide
  5. satisfaire test_mercuriale_seed_prix_coherence
  6. annee_mercuriale + zone renseignÃ©s

INTERDIT : insÃ©rer des valeurs "de mÃ©moire" sans vÃ©rification
           sur le document source officiel.

CONSÃ‰QUENCE : toute PR qui insÃ¨re dans procurement_dictionary
              sans respecter MERCURIALE-001 est bloquÃ©e en CI.
9. Ã‰tat et dÃ©cisions pendantes

ADR-0005 : FROZEN âœ…

Corrections intÃ©grÃ©es :
  âœ… DÃ©blocage PR #85 (5 fixes)
  âœ… C1 â€” score_runs + vue + batch_id + trigger
  âœ… C2 â€” ExtractionResult typÃ© + mapping HTTP
  âœ… C3 â€” codes et valeurs mercuriale vÃ©rifiÃ©s PDF
  âœ… C4 â€” MercurialeValidator + 3 gates CI
  âœ… RÃˆGLE MERCURIALE-001 opposable
